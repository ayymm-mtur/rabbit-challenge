{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 学習率最適化手法について\n",
    "\n",
    "適切な学習率を設定することは、学習の成否に大きく寄与する。学習率が大きすぎれば発散してしまうし、\n",
    "小さすぎると収束までに時間がかかったり、局所解に陥ったりしてしまう。\n",
    "学習率の指針として、最初に設定した学習率を徐々に小さくしていく、パラメータごとに学習率を変えるというアプローチをとる。\n",
    "\n",
    "## 2-1. モメンタム\n",
    "$$\n",
    "\\Delta t = \\mu \\Delta_{t-1} - \\epsilon \\Delta E\\\\\n",
    "w^{t+1} = w^{t} + V_t\n",
    "$$\n",
    "現在の重みから前回の重みを引いたものに慣性をかけたものを、重みの更新に用いる<br>\n",
    "メリット：局所最適解にならない。谷間から最も低い位置までの到達時間が短い\n",
    "\n",
    "## 2-2. Adagrad\n",
    "$$\n",
    "h_0 = \\theta\\\\\n",
    "h_t = h_{t-1} + (\\Delta E)^2\\\\\n",
    "w^{(t+1)} = w^{(t)} - \\epsilon \\frac{1}{\\sqrt{h_t} + \\theta} \\Delta E\n",
    "$$\n",
    "これまでの誤差の二乗をすべて加算したものとハイパーパラメータで、学習率を更新する。<br>\n",
    "メリット：緩やかな斜面で最適値に近づける\n",
    "デメリット：鞍点問題を引き起こすことがある。\n",
    "\n",
    "## 2-3. RMSProp\n",
    "$$\n",
    "\n",
    "$$\n",
    "Adagradの鞍点問題を解消したもの。<br>\n",
    "メリット：局所最適解にならない。ハイパーパラメータの調整が必要な場合が少ない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
