{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.非線形回帰\n",
    "非線形な回帰を考える<br>\n",
    "e.g.)\n",
    "$$\n",
    "y = \\omega_0 + \\omega_1 x + \\omega_2 x^2\\\\\n",
    "y = \\omega_0 + \\omega_1 \\sin(x) + \\omega_2 \\cos(x)\n",
    "$$\n",
    "\n",
    "- 基底展開法<br>\n",
    "回帰関数として既知の非線形関数を用いる。<br>\n",
    "多項式、ガウス関数\n",
    "- ガウス関数<br>\n",
    "hが大きい→xの変化量に対して()の中の数値の変化量が少なくなる→幅が広くなる<br>\n",
    "$$\n",
    "\\phi_i(x) = \\exp(-\\frac{(x-\\mu_i)^2}{2h_i})\n",
    "$$\n",
    "<img src=\"./image/2_3_gaussian_function.jpg\">\n",
    "\n",
    "## 未学習と過学習\n",
    "* 未学習：学習データに対して、十分小さな誤差が得られていない\n",
    "    * 対策：モデルの表現力が低いため、表現力の高いモデルを利用する\n",
    "* 過学習：テスト集合誤差との差が大きいモデル\n",
    "    * 対策１：学習データの数を増やす\n",
    "    * 対策２：不要な基底関数を削除して表現力を抑止\n",
    "    * 対策３：正則化法を利用して表現力を抑止\n",
    "    \n",
    "## 正則化法\n",
    "* パラメータの取りうる値を制限して、最適化を行う\n",
    "    \n",
    "## データの分割\n",
    "* ボールとアウト法\n",
    "    * データを学習用とテスト用の二つに分ける。\n",
    "    * 学習用データを多くすれば、学習制度が良くなり性能評価が悪くなる。逆もまた然り。\n",
    "* クロスバリデーション法\n",
    "    * 分割の仕方をパターン分けして、それぞれでモデルの学習を評価する。\n",
    "\n",
    "## ハイパーパラメータをどのようにして探すか？\n",
    "* グリッドサーチ\n",
    "* ベイズ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
