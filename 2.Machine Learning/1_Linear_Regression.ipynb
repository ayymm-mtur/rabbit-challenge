{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 線形回帰\n",
    "線形：比例関係\n",
    "\n",
    "$$\n",
    "y = Ax + B（直線）\\\\\n",
    "y = Ax + By + c（平面）\\\\\n",
    "y = a_0 + a_1 x_1 + a_2 x_2+ \\cdots + a_{n-1} x_{n-1}\n",
    "$$\n",
    "\n",
    "### 回帰問題\n",
    "ある入力から(離散あるいは連続値)から出力(連続値)を予測する問題\n",
    "\n",
    "### 線形回帰モデル\n",
    "- モデルの一つ\n",
    "- 教師あり学習\n",
    "- 入力と線形パラメータの線形結合を出力する\n",
    "\n",
    "$$\n",
    "パラメータ： \\omega = (\\omega_1 , \\omega_2 , \\cdots , \\omega_m )^T\\\\\n",
    "線形結合：\\hat{y} = \\omega_T x + \\omega_0 = \\sum_{j=1}^{m}\\omega_j x_j + \\omega_0\n",
    "$$\n",
    "\n",
    "パラメータは特徴量が予測値に対してどの程度影響するかを表す。<br>\n",
    "重みが大きければ、その特徴量は予測結果に大きく寄与する。<br>\n",
    "パラメータは最小二乗法で決定する。\n",
    "\n",
    "真のモデルよりも少ない特徴量でモデルを表現すると、用いてない特徴量は誤差$\\epsilon$に吸収されてしまう。\n",
    "例えば下のモデルで、真のモデルでは$x_2$を含んでいるとき、$x_2$は誤差校に吸収されてしまう。\n",
    "$$\n",
    "y = \\omega_0 + \\omega_1 x_1 + \\epsilon\n",
    "$$\n",
    "\n",
    "- 連立方程式<br>\n",
    "連立方程式\n",
    "$$\n",
    "y_1 = \\omega_0 + \\omega_1 x_1 + \\epsilon_1\n",
    "y_2 = \\omega_0 + \\omega_2 x_2 + \\epsilon_2\n",
    "y_n = \\omega_0 + \\omega_n x_n + \\epsilon_n\n",
    "$$\n",
    "\n",
    "行列表現\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & x_1\\\\\n",
    "1 & x_2\\\\\n",
    "\\vdots \\\\\n",
    "1 & x_n\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\omega_0 \\\\\n",
    "\\omega_1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### データの分割とモデルの汎化性能測定\n",
    "- データの分割<br>\n",
    "学習用データ：機械学習モデルの学習に利用するデータ<br>\n",
    "検証用データ：学習済みモデルの制度を検証するためのデータ\n",
    "\n",
    "- 分割する理由\n",
    "モデルがどの程度汎用的であるか検証するため。学習用データのみではなく、未知のデータでは精度の良い予測ができるか？\n",
    "\n",
    "### 最小二乗法\n",
    "- 平均二乗誤差\n",
    "データとモデルの出力の二乗誤差の和\n",
    "$$\n",
    "\\sum (\\hat{y_i} - y_i)^2\n",
    "$$\n",
    "- 最小二乗法\n",
    "平均二乗誤差を最小化する<br>\n",
    "\n",
    "二乗誤差は外れ値に弱い。外れ値に引っ張られる。<br>\n",
    "外れ値に強い損失→Huber損失、Tukey損失\n",
    "<img src=\"./image/2_1_hazure_value.png\">\n",
    "二乗誤差を最小にする$\\omega$とは、二乗誤差を$\\omega$で微分したものが0になる$\\omega$\n",
    "<img src=\"./image/2_2_mse.jpg\">\n",
    "\n",
    "回帰係数\n",
    "$$\n",
    "\\hat{\\omega} = (X^{(train)T}X^{(train)})^{-1} X^{(train)T} y^{train}\n",
    "$$\n",
    "予測値\n",
    "$$\n",
    "\\hat{y} = X(X^{(train)T}X^{(train)})^{-1} X^{(train)T} y^{train}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
